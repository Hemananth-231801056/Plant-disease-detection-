# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nZR045FT4As3rdQjeWaMrE668DT8W2Dm
"""

!pip install tensorflow split-folders matplotlib

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import splitfolders
from tensorflow.keras.preprocessing import image
from google.colab import files

!wget -O "dataset.zip" "https://data.mendeley.com/public-files/datasets/tywbtsjrjv/files/b4e3a32f-c0bd-4060-81e9-6144231f2520/file_downloaded"
!unzip -q dataset.zip -d /content/


splitfolders.ratio(
    '/content/Plant_leave_diseases_dataset_with_augmentation',
    output="/content/dataset",
    seed=42,
    ratio=(0.8, 0.1, 0.1)
)


train_dir = "/content/dataset/train"
val_dir   = "/content/dataset/val"
test_dir  = "/content/dataset/test"

BATCH_SIZE = 32
IMG_SIZE = (160, 160)

import tensorflow as tf

train_ds = tf.keras.utils.image_dataset_from_directory(
    train_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE
)
val_ds = tf.keras.utils.image_dataset_from_directory(
    val_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE
)
test_ds = tf.keras.utils.image_dataset_from_directory(
    test_dir, shuffle=False, batch_size=BATCH_SIZE, image_size=IMG_SIZE
)

class_names = train_ds.class_names
print("Classes:", class_names)

AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)
val_ds   = val_ds.prefetch(buffer_size=AUTOTUNE)
test_ds  = test_ds.prefetch(buffer_size=AUTOTUNE)

preprocess_input = tf.keras.applications.efficientnet.preprocess_input
IMG_SHAPE = IMG_SIZE + (3,)

base_model = tf.keras.applications.EfficientNetB0(
    input_shape=IMG_SHAPE,
    include_top=False,
    weights='imagenet'
)
base_model.trainable = False  # Freeze base

inputs = tf.keras.Input(shape=IMG_SHAPE)
x = preprocess_input(inputs)
x = base_model(x, training=False)
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Dropout(0.2)(x)
outputs = tf.keras.layers.Dense(len(class_names), activation='softmax')(x)

model = tf.keras.Model(inputs, outputs)
model.compile(
    optimizer=tf.keras.optimizers.Adam(),
    loss=tf.keras.losses.SparseCategoricalCrossentropy(),
    metrics=['accuracy']
)
model.summary()

initial_epochs = 3
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=initial_epochs
)

base_model.trainable = True
fine_tune_at = 100
for layer in base_model.layers[:fine_tune_at]:
    layer.trainable = False

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),
    loss=tf.keras.losses.SparseCategoricalCrossentropy(),
    metrics=['accuracy']
)

fine_tune_epochs = 5
total_epochs = initial_epochs + fine_tune_epochs
history_fine = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=total_epochs,
    initial_epoch=initial_epochs
)

loss, accuracy = model.evaluate(test_ds)
print("Test Accuracy:", round(accuracy * 100, 2), "%")

model.save("/content/plant_disease_recognition_model.keras")
print("Model saved successfully!")

import tensorflow as tf # Import tensorflow
from tensorflow.keras.preprocessing import image # Import image from keras.preprocessing
import numpy as np # Import numpy
import matplotlib.pyplot as plt # Import matplotlib
from google.colab import files # Import files from google.colab

reloaded_model = tf.keras.models.load_model("/content/plant_disease_recognition_model.keras")


predict_uploaded_image(reloaded_model, class_names)

import tensorflow as tf # Import tensorflow
from tensorflow.keras.preprocessing import image # Import image from keras.preprocessing
import numpy as np # Import numpy
import matplotlib.pyplot as plt # Import matplotlib
from google.colab import files # Import files from google.colab

reloaded_model = tf.keras.models.load_model("/content/plant_disease_recognition_model.keras")


predict_uploaded_image(reloaded_model, class_names)

